# Generative-AI-With-LLMs-by-Coursera
This repository contains Labs, PPTs, Resources and Handwritten Notes for [Generative AI With Large Language Models](https://www.coursera.org/learn/generative-ai-with-llms) offered by DeepLearing.AI and AWS.  

You can Chekout My Certificate : https://www.coursera.org/account/accomplishments/verify/YR8HQKTW9ARW 

## Week 1

#### Generative AI use cases, project lifecycle, and model pre-training
##### Learning Objectives
- Discuss model pre-training and the value of continued pre-training vs fine-tuning
- Define the terms Generative AI, large language models, prompt, and describe the transformer architecture that powers LLMs
- Describe the steps in a typical LLM-based, generative AI model lifecycle and discuss the constraining factors that drive decisions at each step of model lifecycle
- Discuss computational challenges during model pre-training and determine how to efficiently reduce memory footprint
- Define the term scaling law and describe the laws that have been discovered for LLMs related to training dataset size, compute budget, inference requirements, and other factors.


#### Links

- [Notes](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/tree/b8f188a1b35f257ffeaded6b914be2ec8e14eac5/Week%201/Notes)
- [Handwritten Notes](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/tree/b8f188a1b35f257ffeaded6b914be2ec8e14eac5/Week%201/Handwritten%20Notes)
- [Week 1 PPT](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/blob/b8f188a1b35f257ffeaded6b914be2ec8e14eac5/Week%201/Week%201.pdf )
- [Week 1 Lab](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/blob/b8f188a1b35f257ffeaded6b914be2ec8e14eac5/Week%201/Lab_1_summarize_dialogue.ipynb)
- [Week 1 Resources](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/blob/b8f188a1b35f257ffeaded6b914be2ec8e14eac5/Week%201/Week%201%20resources.pdf)



<br/>

## Week 2

#### Fine-tuning and evaluating large language models
##### Learning Objectives
- Describe how fine-tuning with instructions using prompt datasets can improve performance on one or more tasks
- Define catastrophic forgetting and explain techniques that can be used to overcome it
- Define the term Parameter-efficient Fine Tuning (PEFT)
- Explain how PEFT decreases computational cost and overcomes catastrophic forgetting
- Explain how fine-tuning with instructions using prompt datasets can increase LLM performance on one or more tasks


#### Links
- [Notes](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/tree/4b49e2b9bb68ba1c80c42c3301908b875ef06ae4/Week%202/Notes)
- [Handwritten Notes](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/tree/adaeba6f63e2b6e1a8ebc8ef9b6a74f4e8bc7d35/Week%202/Handwritten%20Notes)
- [Week 2 PPT](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/blob/adaeba6f63e2b6e1a8ebc8ef9b6a74f4e8bc7d35/Week%202/Week%202.pdf)
- [Week 2 Lab](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/blob/adaeba6f63e2b6e1a8ebc8ef9b6a74f4e8bc7d35/Week%202/Lab_2_fine_tune_generative_ai_model.ipynb)
- [Week 2 Resources](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/blob/adaeba6f63e2b6e1a8ebc8ef9b6a74f4e8bc7d35/Week%202/Week%202%20Resources.pdf)

<br/>

## Week 3

#### Reinforcement learning and LLM-powered applications
##### Learning Objectives
- Describe how RLHF uses human feedback to improve the performance and alignment of large language models
- Explain how data gathered from human labelers is used to train a reward model for RLHF
- Define chain-of-thought prompting and describe how it can be used to improve LLMs reasoning and planning abilities
- Discuss the challenges that LLMs face with knowledge cut-offs, and explain how information retrieval and augmentation techniques can overcome these challenges

#### Links
- [Notes](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/tree/48268093b44c54075da4e37cd3f4d1af5abf0fc7/Week%203/Notes)
- [Handwritten Notes]()
- [Week 3 PPT](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/blob/48268093b44c54075da4e37cd3f4d1af5abf0fc7/Week%203/Week%203.pdf)
- [Week 3 Lab](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/blob/84e07628dd22d160d902ba8a92c75d8af1a501fe/Week%203/Lab_3_fine_tune_model_to_detoxify_summaries.ipynb)
- [Week 3 Resources](https://github.com/Kshitij-Darwhekar/Generative-AI-With-LLMs-by-Coursera/blob/48268093b44c54075da4e37cd3f4d1af5abf0fc7/Week%203/Week%203%20resources.pdf)

<br/>
<br/>
<br/>
<br/>
<br/>


## Copyright Notice

### Introduction
This repository contains presentation slides and code provided by DeepLearning.AI. The materials shared here are intended for educational purposes only, in accordance with DeepLearning.AI's policies.

### Usage and Attribution
The resources provided by DeepLearning.AI have been instrumental in my learning journey, and I am sharing them here to help others benefit from the same high-quality educational content. In compliance with DeepLearning.AI's guidelines, proper credit has been given to DeepLearning.AI throughout this repository.

### Educational Purpose
All materials in this repository are shared with the sole intent of fostering education and learning. They are not intended for commercial use or profit. By sharing these resources, I aim to contribute to the community of learners and practitioners in the field of deep learning and artificial intelligence.

### Credit to DeepLearning.AI
Every presentation slide and piece of code in this repository includes an acknowledgment to DeepLearning.AI, recognizing their valuable contribution to the educational content. This ensures that the original creators are appropriately credited for their work.

### Conclusion
By adhering to the guidelines provided by DeepLearning.AI, this repository serves as a platform for knowledge sharing while respecting the intellectual property rights of the original creators. If you have any questions or concerns regarding the materials shared here, please feel free to contact me.

